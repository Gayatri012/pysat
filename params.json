{"name":"Pysat","tagline":"Science data analysis library designed to minimize the overhead when analyzing science data across measurement platforms. ","body":"#What is it\r\nThe Python Science Analysis Toolkit (pysat) is a package providing a simple and flexible interface\r\nfor downloading, loading, cleaning, managing, processing, and analyzing scientific \r\nmeasurements. Though pysat was initially designed for in-situ\r\nsatellite based measurements it aims to support all instruments in space science.\r\n\r\n#Main Features\r\n* Single interface for a wide variety of science data sets.\r\n* Single interface to download data for all supported instruments.\r\n* Data model (modified pandas) that supports a combination of 1D, 2D, 3D, and nD data in a single structure\r\n* Instrument independent analysis routines.\r\n* Science data pipeline tasks of identifying files, loading, and cleaning\r\ndata sets are built into the instrument object. \r\n* Supports the automatic application of arbitray custom functions \r\n upon each load. This nano-kernel funcitonality ensures that any routine that\r\n interacts with the instrument object receives properly processed data.\r\n* Supports metadata consistent with the netCDF CF-1.6 standard. Each variable \r\nhas a name, long name, and units. Note units are informational only.\r\n* Simplifies data management\r\n  * Iterates by day/file using the for loop, manual next/prev methods, or any iterative\r\n  method.\r\n  * Iterate through a data set orbit-by-orbit; orbits are calculated on the fly\r\nfrom loaded data and span day/month/year breaks.\r\n  * Iterate over custom seasons\r\n* Supports rigorous time-series calculations. Frequently these methods need\r\ntime to spin up and down to produce accurate analysis. The instrument object\r\nappends real data for a buffer on each end of desired data, applies the custom \r\nfunctions, then removes buffer data before presenting output. The time\r\nseries code does not need to do anything to support this behavior. \r\n* Uses pandas for the underlying underlying data structure;\r\ncapable of handling the many forms scientific measurements take in a consistent\r\nmanner.\r\n  * pandas has been forked to accomodate the assignment of pandas Series/\r\n  Dateframes as single elements of a Series/Dataframe.\r\n* Includes helper functions to reduce the barrier to adding new science instruments to pysat\r\n\r\n\r\n#Installation\r\n##Starting from scratch\r\n* One simple way to get a complete science python package is from [enthought](https://store.enthought.com)\r\n* Download and install NASA CDF [library](http://cdf.gsfc.nasa.gov/html/sw_and_docs.html) \r\n* Download and install netcdf-4 [library](http://www.unidata.ucar.edu/downloads/netcdf/index.jsp) \r\n* at command line type\r\n```\r\npip install pysat\r\n```\r\n* in python, run pysat.utils.set_data_dir('path to top level data dir')\r\n  * Nominal organization of data is top_dir/platform/name/tag/*/files\r\n* To get the forked pandas, needed for full support of mixed data types.\r\n```\r\npip install git+https://github.com/rstoneback/pandas.git\r\n```\r\nIt is hoped that the needed changes will be pulled into main pandas.\r\n\r\n#Quick Demo\r\nThe core functionality is exposed through the Instrument object, providing a single\r\nlocation to obtain instrument data and properties. See pysat/demo for more.\r\n```\r\nimport pysat\r\nivm = pysat.Instrument(platform='cnofs', name='ivm', tag='', clean_level='clean')\r\n# 1-second thermal plasma parameters\r\nivm.load(2009,1)\r\n\r\nvefi = pysat.Instrument('cnofs','vefi','dc_b', 'clean')\r\n# 1-second mag field data\r\nvefi.load(date=pds.datetime(2009,1,1))\r\n\r\ncosmic = pysat.Instrument('cosmic2013', 'gps', 'ionprf')\r\n# gps occultation, vertical electron density profiles\r\ncosmic.load(fname='filename')\r\nor\r\ncosmic.load(2009,1)\r\n```\r\npysat calls functions written specifically for the given instrument, in this\r\ncase the Ion Velocity Meter onboard C/NOFS, part of the Coupled Ion\r\nNeutral Dynamics Investigation (CINDI), to enable loading and cleaning.\r\n\r\n##Download Data\r\nDownload data easily onto your filesystem.\r\n```\r\nimport pysat\r\nimport pandas as pds\r\n# 1-second mag field data\r\nvefi = pysat.Instrument('cnofs','vefi','dc_b', 'clean')\r\nstart = pds.datetime(2010, 3, 4)\r\nstop = pds.datetime(2010, 3, 8)\r\nvefi.download(start, stop)\r\n```\r\n```\r\nimport pysat\r\nimport pandas as pds\r\ncosmic = pysat.Instrument('cosmic2013','gps', tag='ionprf', clean_level='clean')\r\nstart = pds.datetime(2009,1,2)\r\nstop = pds.datetime(2009,1,3)\r\n# requires CDAAC account \r\ncosmic.download(start, stop, user='', password='')\r\ncosmic.load(date=start)\r\n# the profiles column has a DataFrame in each element which stores\r\n# all relevant profile information indexed by altitude\r\n# print part of the first profile, selection by integer location\r\nprint cosmic[0,'profiles'].iloc[55:60]\r\n# print part of profile, selection by alitude value\r\nprint cosmic[0,'profiles'].ix[208:220]\r\n\r\n```\r\n\r\n\r\n##Data Access\r\n* ivm['name'] or ivm.data['name']\r\n* ivm[row,'name'], ivm[row1:row2,'name'], ivm[[1,2,3], 'name']\r\n* ivm[datetime,'name'], ivm[datetime1:datetime2,'name']\r\n* complete pandas data object exposed in ivm.data\r\n\r\n##Data Assignment\r\n```\r\nivm['new_data'] = new_data\r\n```\r\n#####Assignment with metadata\r\n```\r\nivm['double_mlt'] = {'data':2.*inst['mlt'], 'long_name':'Double MLT', \r\n                     'units':'hours'}\r\n```\r\n##Custom Functions\r\nScience analysis is built upon custom data processing, thus custom functions \r\nmay be attached to the Instrument object. Each function is \r\nrun automatically when new data is loaded.\r\n\r\n#####Modify Functions\r\nThe instrument object is passed to function without copying, modify in place\r\n```\r\ndef custom_func_modify(inst, optional_param=False):\r\n    inst['double_mlt'] = 2.*inst['mlt']\r\n```    \r\n#####Add Functions\r\nA copy of the instrument is passed to function, data to be added is returned\r\n```\r\ndef custom_func_add(inst, optional_param=False):\r\n    return 2*.inst['mlt']\r\n```\r\n#####Add Function Including Metadata\r\n```\r\ndef custom_func_add(inst, optional_param1=False, optional_param2=False):\r\n    return {'data':2.*inst['mlt'], 'name':'double_mlt', \r\n            'long_name':'doubledouble', 'units':'hours'}\r\n```\r\n#####Attaching Custom Function\r\n```\r\nivm.custom.add(custom_func_modify, 'modify', optional_param2=True)\r\nivm.load(2009,1)\r\nprint ivm['double_mlt']\r\n```\r\n```\r\nivm.custom.add(custom_func_add, 'add', optional_param2=True)\r\nivm.bounds = (start,stop)\r\ncustom_complicated_analysis_over_season(ivm)\r\n```\r\nThe output of custom_func_modify will always be available from instrument object, regardless\r\nof what level the science analysis is performed.\r\n\r\n##Iterate over Dataset\r\n#####Iterate by day\r\nEach loop loads a new day of instrument data, with custom processing\r\n```\r\nfor ivm in ivm:\r\n    print 'new day of double mlt ivm data ', ivm['double_mlt']\r\n```   \r\n#####Iterate over custom season\r\n```\r\nimport pandas as pd\r\nstart = [pd.datetime(2009,1,1), pd.datetime(2010,1,1)]\r\nstop = [pd.datetime(2009,4,1), pd.datetime(2010,4,1)]\r\nivm.bounds = (start, stop)\r\nfor ivm in ivm:\r\n    print 'A new day of data in custom season, ', ivm.date.strftime('%y/%m/%d')\r\n    print 'Year, doy ', ivm.yr, ivm.doy\r\n```\r\n#####Iterate by orbit over custom season:\r\n```\r\ninfo = {'index':'mlt', 'kind':'local time'}\r\nivm = pysat.Instrument(platform='cnofs', name='ivm', tag='', \r\n                       clean_level='clean', orbit_info=info)\r\nstart = [pd.datetime(2009,1,1), pd.datetime(2010,1,1)]\r\nstop = [pd.datetime(2009,4,1), pd.datetime(2010,4,1)]\r\nivm.bounds = (start, stop)\r\nfor ivm in ivm.orbits:\r\n    print 'next available orbit ', ivm.data\r\n```\r\n#Data Model\r\nThe base object is the pandas DataFrame, \"similar\" to an excel spreadsheet\r\nwith labeled rows and columns. Nominally rows are indexed by time, while\r\ncolumns span the different data types. This accomodates 1D data quite well.\r\nFor higher order data sets, a pandas series or pandas DataFrame may also be stored\r\nwithin each cell of a column, with 1D or other dimensional data in other columns.\r\nThis set up allows for all data types to be stored in a single data object.\r\n\r\nA powerful feature of pandas is auto-alignment of data based upon the index.\r\nThus, the profiles or images stored as above do not need to have the same sizes.\r\nMath operations across series and dataframes are aligned and missing data is treated as dictated.\r\n\r\n#Adding a new instrument to pysat\r\npysat works by calling modules written for specific instruments\r\nthat load and process the data consistent with the pysat standard. The name\r\nof the module corresponds to the combination 'platform_name' provided when initializing a pysat\r\ninstrument object. The module should be placed in the pysat instruments\r\ndirectory or in the user specified location (via mechanism to be added) \r\nfor automatic discovery. A compatible module may also be supplied directly\r\nto pysat.Instrument(inst_module=input module) if it also contains attributes platform and name. \r\n\r\n#### Required Routines\r\nThree functions are required:\r\n###### List Files\r\n* list_files routine that returns a pandas Series\r\nwith filenames ordered in time. \r\n  * The\r\n  nominal location of data is pysat_data_dir/platform/name/tag, provided in data_path, where pysat_data_dir\r\n  is specified by user in pysat settings.\r\n```\r\ndef list_files(tag=None, data_path=None):\r\n    return pds.Series(files, index=datetime_index)\r\n```\r\n  * pysat.Files.from_os is a convenience constructor provided for filenames that include time information in the filename and utilize a constant field width. The location and format of the time information is specified using standard python formatting and keywords year, month, day, hour, minute, second. \r\n```\r\ndef list_files(tag=None, data_path=None):\r\n    return pysat.Files.from_os(data_path=data_path, \r\n                    format_str='rs{year:4d}{day:03d}-ivm.hdf')\r\n```                                \r\n###### Load Data\r\n* load routine that returns a tuple with (data, pysat metadata object)\r\n  * data is a pandas DataFrame, column names are the data labels, rows are indexed by datetime objects\r\n  * pysat meta object obtained from pysat.Meta(). Use pandas DataFrame indexed\r\nby name with columns for 'units' and 'long_name'. Additional arbitrary columns allowed.\r\nConvenience function from_csv provided.\r\n```\r\ndef load(fnames, tag=None):\r\n    return data, meta\r\n```\r\n###### Download Data\r\n* download routine to fetch data from the internet\r\n```\r\ndef download(date_array, data_path=None, user=None, password=None):\r\n    return\r\n```\r\n#### Optional Routines\r\n###### Initiliaze\r\n* init routine, initialize any specific instrument info. Runs once. (optional)\r\n```\r\ndef init(inst):\r\n    return None\r\n```\r\n###### Default\r\n* default routine, runs once per instrument load. inst is pysat instrument object. (optional)\r\n```\r\ndef default(inst):\r\n    return None\r\n```\r\n###### Clean Data\r\n* clean routine, cleans instrument for levels supplied in inst.clean_level. (optional)\r\n  * 'clean' : expectation of good data\r\n  * 'dusty' : probably good data, use with caution\r\n  * 'dirty' : minimal cleaning, only blatant instrument errors removed\r\n  * 'none'  : no cleaning, routine not called\r\n```\r\ndef clean(inst):\r\n    return None\r\n```\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}